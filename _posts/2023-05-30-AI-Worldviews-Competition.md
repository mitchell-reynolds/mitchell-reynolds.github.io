---
title: AI Worldviews Contest
published: false
categories:
- agi
---

_See contest details [here](https://www.openphilanthropy.org/open-philanthropy-ai-worldviews-contest/)._

> Conditional on AGI being developed by 2070, what is the probability that humanity will suffer an existential catastrophe due to loss of control over an AGI system?

## What?
Define AGI, existential catastrophe,

## Who?
If AGI is possible earlier, it'll be backed by large nation states (USA, China etc.) if they're able to prioritize budgets.
If AGI is possible slightly later, it'll be developed by a large tech/research company (Alphabet [Google Brain, Deepmind, Anthropic], Microsoft [OpenAI] etc.).
And later still, AGI could be either of the above but scaled down versions to include Canada, UK and various EU countries [Marco Polo](https://macropolo.org/digital-projects/the-global-ai-talent-tracker/) or today's winners in narrow AI (Cohere, Fathom etc.)

## How?
Given the various rankings of the "who are the players", I will build a model 

## When?
